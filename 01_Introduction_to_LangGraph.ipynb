{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Introduction to LangGraph\n",
        "\n",
        "Welcome to your LangGraph learning journey! This notebook will introduce you to the fundamental concepts of LangGraph and help you set up your development environment.\n",
        "\n",
        "## What is LangGraph?\n",
        "\n",
        "LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain by adding the ability to coordinate multiple chains (or actors) across multiple computational steps in a cyclic manner.\n",
        "\n",
        "### Key Concepts:\n",
        "- **State Machines**: LangGraph is built on the concept of state machines\n",
        "- **Nodes**: Individual computational steps\n",
        "- **Edges**: Connections between nodes that define the flow\n",
        "- **State**: The data that flows through your graph\n",
        "\n",
        "## Learning Objectives\n",
        "\n",
        "By the end of this notebook, you will:\n",
        "1. Understand what LangGraph is and when to use it\n",
        "2. Set up your development environment\n",
        "3. Create your first simple LangGraph application\n",
        "4. Understand the basic components of a LangGraph workflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Environment Setup\n",
        "\n",
        "First, let's install the required packages and set up our environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages (run this cell if you haven't already)\n",
        "# !pip install langgraph langchain langchain-openai python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "from typing import TypedDict, Annotated\n",
        "from typing_extensions import TypedDict\n",
        "import json\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Initialize the LLM\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0,\n",
        "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
        ")\n",
        "\n",
        "print(\"\u2705 Environment setup complete!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Understanding LangGraph Components\n",
        "\n",
        "Let's break down the main components of LangGraph:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### State\n",
        "\n",
        "State is the data that flows through your graph. It's typically defined as a TypedDict:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define our state structure\n",
        "class AgentState(TypedDict):\n",
        "    \"\"\"The state of our agent.\"\"\"\n",
        "    messages: Annotated[list, \"The messages in the conversation\"]\n",
        "    current_step: Annotated[str, \"The current step in the process\"]\n",
        "    result: Annotated[str, \"The final result\"]\n",
        "\n",
        "print(\"\u2705 State structure defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Nodes\n",
        "\n",
        "Nodes are functions that process the state and return updated state:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define a simple node function\n",
        "def process_message(state: AgentState) -> AgentState:\n",
        "    \"\"\"Process the latest message in the conversation.\"\"\"\n",
        "    # Get the latest message\n",
        "    latest_message = state[\"messages\"][-1]\n",
        "    \n",
        "    # Generate a response using the LLM\n",
        "    response = llm.invoke(f\"Respond to: {latest_message.content}\")\n",
        "    \n",
        "    # Update the state\n",
        "    state[\"messages\"].append(response)\n",
        "    state[\"current_step\"] = \"processed\"\n",
        "    state[\"result\"] = response.content\n",
        "    \n",
        "    return state\n",
        "\n",
        "print(\"\u2705 Node function defined!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Creating Your First LangGraph Application\n",
        "\n",
        "Now let's create a simple graph that processes messages:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create the graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add the node\n",
        "workflow.add_node(\"process_message\", process_message)\n",
        "\n",
        "# Set the entry point\n",
        "workflow.set_entry_point(\"process_message\")\n",
        "\n",
        "# Add the end point\n",
        "workflow.add_edge(\"process_message\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"\u2705 Graph created and compiled!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Running Your First Graph\n",
        "\n",
        "Let's test our simple graph:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create initial state\n",
        "initial_state = {\n",
        "    \"messages\": [\n",
        "        {\"role\": \"user\", \"content\": \"Hello! Can you tell me a joke?\"}\n",
        "    ],\n",
        "    \"current_step\": \"start\",\n",
        "    \"result\": \"\"\n",
        "}\n",
        "\n",
        "# Run the graph\n",
        "result = app.invoke(initial_state)\n",
        "\n",
        "print(\"\ud83c\udf89 Your first LangGraph application worked!\")\n",
        "print(f\"\\nFinal result: {result['result']}\")\n",
        "print(f\"\\nTotal messages: {len(result['messages'])}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Understanding the Flow\n",
        "\n",
        "Let's visualize what happened:\n",
        "\n",
        "1. **Initial State**: We started with a user message\n",
        "2. **Node Processing**: The `process_message` node processed the message\n",
        "3. **State Update**: The state was updated with the LLM's response\n",
        "4. **End**: The graph reached the END node\n",
        "\n",
        "This is the simplest possible LangGraph application!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Exercise: Modify the Graph\n",
        "\n",
        "Try modifying the graph to add another node that formats the response. Here's a template:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Exercise: Add a formatting node\n",
        "def format_response(state: AgentState) -> AgentState:\n",
        "    \"\"\"Format the response to make it more readable.\"\"\"\n",
        "    # Your code here\n",
        "    # Hint: Modify the result to add some formatting\n",
        "    return state\n",
        "\n",
        "# Create a new graph with both nodes\n",
        "# Your code here\n",
        "\n",
        "print(\"Try implementing the formatting node!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Key Takeaways\n",
        "\n",
        "### What we learned:\n",
        "1. **State**: How to define and manage state in LangGraph\n",
        "2. **Nodes**: How to create functions that process state\n",
        "3. **Graphs**: How to connect nodes to create workflows\n",
        "4. **Execution**: How to run and test your graphs\n",
        "\n",
        "### Next Steps:\n",
        "In the next notebook, we'll explore more complex state management patterns and learn how to create more sophisticated workflows.\n",
        "\n",
        "## 8. Challenge\n",
        "\n",
        "Try creating a graph that:\n",
        "1. Takes a user question\n",
        "2. Generates multiple possible answers\n",
        "3. Picks the best one\n",
        "4. Formats it nicely\n",
        "\n",
        "This will help you understand how to chain multiple nodes together!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "Congratulations! You've successfully:\n",
        "- \u2705 Set up your LangGraph development environment\n",
        "- \u2705 Created your first LangGraph application\n",
        "- \u2705 Understood the basic components (State, Nodes, Graphs)\n",
        "- \u2705 Run a simple workflow\n",
        "\n",
        "You're now ready to move on to more complex patterns in the next notebook!"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}